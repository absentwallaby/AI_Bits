{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMYJwAZat75E4k3+hDA0qxl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["===================<br>\n","**First Section**  \n","1. connect to storage - this section is the primary one to be changed if not using google colab\n","2. define all the data paths\n","3. download the 25k image dataset, and extract it to the local machine (not remote storage)\n"],"metadata":{"id":"3oA12p7DY_Lh"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Gc_E7oa5Jrz","executionInfo":{"status":"ok","timestamp":1696400399337,"user_tz":-660,"elapsed":2958,"user":{"displayName":"Nick Eales","userId":"12867207549321056565"}},"outputId":"2f33fcad-b776-42ea-94e2-0422c9362f2d","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","creating /content/drive/MyDrive/output\n"]}],"source":["# @title\n","# 1\n","# connect to colab\n","#configure all paths / folders to use for rest of notebook\n","# download and extract dataset\n","\n","gdrive_path='/content/drive'\n","import os,zipfile\n","#import shutils\n","from google.colab import drive\n","drive.mount(gdrive_path)\n","dataset_source_address='https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n","dataset_filename='kagglecatsanddogs_5340.zip'\n","dataset_gdrive_zip_folder=os.path.join(gdrive_path,'MyDrive','dataset_zips')\n","dataset_gdrive_zip_file=os.path.join(dataset_gdrive_zip_folder,dataset_filename)\n","dataset_parentdir='/tmp/data/'\n","temp_complete_dataset_dir=os.path.join(dataset_parentdir,'PetImages')\n","dataset_dir=os.path.join(dataset_parentdir,'splitdata')\n","dataset_temp_zip=os.path.join('/tmp',dataset_filename)\n","output_dir=os.path.join(gdrive_path,'MyDrive','output')\n","\n","if not os.path.isdir(dataset_parentdir):\n","    print(f'creating {dataset_parentdir}')\n","    os.mkdir(dataset_parentdir)\n","if not os.path.isdir(output_dir):\n","    print(f'creating {output_dir}')\n","    os.mkdir(output_dir)\n","\n","if not os.path.isdir(dataset_gdrive_zip_folder):\n","    print(f'creating {dataset_gdrive_zip_folder}')\n","    os.mkdir(dataset_gdrive_zip_folder)\n","\n","if not os.path.isfile(dataset_gdrive_zip_file):\n","  print(f'wget -P {dataset_gdrive_zip_folder} {dataset_source_address} ')\n","  !wget -P {dataset_gdrive_zip_folder} {dataset_source_address}\n","\n","if not os.path.isdir(temp_complete_dataset_dir):\n","  with zipfile.ZipFile(dataset_gdrive_zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(dataset_parentdir)\n","\n"]},{"cell_type":"markdown","source":["===================<br>\n","**Second section**.\n","- This is used to clean the dataset. Process for this was taken from the Keras examples at  https://keras.io/examples/vision/image_classification_from_scratch/"],"metadata":{"id":"V-0YSP2KZbh_"}},{"cell_type":"code","source":["# @title\n","# 2\n","# Clean dataset\n","\n","#from here https://keras.io/examples/vision/image_classification_from_scratch/\n","import os\n","import tensorflow as tf\n","\n","print(\"cleaning dataset (removing files that don't have the required header)\")\n","\n","num_skipped = 0\n","for folder_name in (\"Cat\", \"Dog\"):\n","    folder_path = os.path.join(temp_complete_dataset_dir, folder_name)\n","    for fname in os.listdir(folder_path):\n","        fpath = os.path.join(folder_path, fname)\n","        try:\n","            fobj = open(fpath, \"rb\")\n","            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n","        finally:\n","            fobj.close()\n","\n","        if not is_jfif:\n","            num_skipped += 1\n","            # Delete corrupted image\n","            os.remove(fpath)\n","\n","print(\"Deleted %d images\" % num_skipped)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELvssY_w6zJ_","executionInfo":{"status":"ok","timestamp":1696400192636,"user_tz":-660,"elapsed":3905,"user":{"displayName":"Nick Eales","userId":"12867207549321056565"}},"outputId":"296d8636-2635-4954-c089-e607db882af9","cellView":"form"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cleaning dataset (removing files that don't have the required header)\n","Deleted 1590 images\n"]}]},{"cell_type":"markdown","source":["===================<br>\n","**Third section**\n","- Splits the dataset into a classic train/validation/test split.\n","- This cannot be done using the tensorflow commands as that causes the memory to be exhausted for google colab"],"metadata":{"id":"AMfAZRnGZqX8"}},{"cell_type":"code","source":["# @title\n","# 3\n","#Split cleaned dataset - doing this at the folder level to avoid OOM errors on Colab\n","\n","!pip install split-folders\n","\n","import splitfolders\n","\n","if not os.path.isdir(dataset_dir):\n","  print(f'creating {dataset_dir}')\n","  os.mkdir(dataset_dir)\n","\n","  print('splitting dataset into train/validation/test')\n","  splitfolders.ratio(input=temp_complete_dataset_dir, output=dataset_dir, ratio=(.8, 0.1,0.1))\n","\n","print('dataset parentdir folder:')\n","print(os.listdir(dataset_parentdir))\n","\n","print('dataset folder:')\n","print(os.listdir(dataset_dir))\n","\n","train_dataset_dir=os.path.join(dataset_dir,'train')\n","val_dataset_dir=os.path.join(dataset_dir,'val')\n","test_dataset_dir=os.path.join(dataset_dir,'test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"PAF97ZDQW8Rl","executionInfo":{"status":"ok","timestamp":1696400234060,"user_tz":-660,"elapsed":10629,"user":{"displayName":"Nick Eales","userId":"12867207549321056565"}},"outputId":"bbcaabf9-be8b-43d1-bc81-0bdfd426bf2e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n","creating /tmp/data/splitdata\n","splitting dataset into train/validation/test\n"]},{"output_type":"stream","name":"stderr","text":["Copying files: 23412 files [00:05, 4107.57 files/s]"]},{"output_type":"stream","name":"stdout","text":["dataset parentdir folder:\n","['splitdata', 'readme[1].txt', 'PetImages', 'CDLA-Permissive-2.0.pdf']\n","dataset folder:\n","['train', 'val', 'test']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["===================<br>\n","**Fourth section**\n","1. check the number of classes in the dataset (at this point the folder structure should be dataset_dir\\train\\class1\\image1.jpg)\n","2. based on the number of classes, determine if we are doing binary classification or categorical classification and set variables appropriately for later use.\n","3. configure data augmentation to use (randomly change images)\n","4. Build the model to use.\n","\n","Parameters for this section - are\n","1. the Network architecture to use.\n","2. Whether to use pre-trained weights (weights='imagenet') or random weights (weights=None)"],"metadata":{"id":"gVNFsXfLaDrL"}},{"cell_type":"code","source":["# @title\n","# 4\n","# check dataset for number of classes & set variables\n","# load model\n","import tensorflow as tf\n","print(f'TensorFlow version: {tf.__version__}')\n","\n","architecture='xception'\n","weights='imagenet'\n","# set weights to 'imagenet' or None\n","\n","n_classes=max(len(os.listdir(train_dataset_dir)),len(os.listdir(val_dataset_dir)),len(os.listdir(test_dataset_dir)))\n","if(n_classes>2):\n","    label_mode='categorical'\n","    loss_function=tf.keras.losses.CategoricalCrossentropy\n","    prediction_layer=tf.keras.layers.Dense(n_classes,activation='softmax')\n","else:\n","    label_mode='binary'\n","    loss_function=tf.keras.losses.BinaryCrossentropy\n","    prediction_layer=tf.keras.layers.Dense(1,activation='sigmoid')\n","\n","#Clear any already loaded data\n","tf.keras.backend.clear_session()\n","\n","tfKerasApps=tf.keras.applications\n","base_arch_func=None\n","base_model=None\n","# get model name and preprocessing functions for the provided architecture\n","# e.g. tf.keras.applications.vgg16\n","try:\n","    base_arch_func=getattr(tfKerasApps, architecture)\n","    archDisplayName=dir(base_arch_func)[0]\n","    base_model_func=getattr(base_arch_func, archDisplayName)\n","    preprocess_input=getattr(base_arch_func, 'preprocess_input')\n","except AttributeError:\n","    print(f'function not found - was architecture correctly provided?')\n","\n","tf.keras.backend.clear_session()\n","\n","#Get model shapes by loading a temporary version of the model\n","temp_model=base_model_func(weights=None)\n","preferred_input_shape=temp_model.get_build_config().get('input_shape')[1:]\n","preferred_image_size=preferred_input_shape[:2]\n","temp_model=None\n","\n","tf.keras.backend.clear_session()\n","\n","print(f'building {archDisplayName} model')\n","\n","#print(f'loading {archDisplayName} model with {weights} weights')\n","base_model=base_model_func(\n","    include_top=False,\n","    weights=weights,\n","    input_shape=preferred_input_shape,\n","    pooling='avg')\n","\n","if(weights == 'imagenet'):\n","  base_model.trainable = False\n","\n","# randomize things a bit mre with the training images:\n","augments=[]\n","augments_name=''\n","\n","augments_name=augments_name+'Flip'\n","augments = augments + [tf.keras.layers.RandomFlip('horizontal')]\n","augments_name=augments_name+'Rotate'\n","augments = augments + [tf.keras.layers.RandomRotation(30)]\n","augments_name=augments_name+'Zoom'\n","augments = augments + [tf.keras.layers.RandomZoom(0.2)]\n","augments_name='Random'+augments_name\n","data_augmentation = tf.keras.Sequential(augments,name=augments_name)\n","\n","\n","#print (f'n_classes: {n_classes}')\n","inputs = tf.keras.Input(shape=preferred_input_shape)\n","x = data_augmentation(inputs)\n","x = preprocess_input(x)\n","x = base_model(x, training=False)\n","x = tf.keras.layers.Dropout(0.5)(x)\n","outputs = prediction_layer(x)\n","model = tf.keras.Model(inputs, outputs)\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                    loss=loss_function(from_logits=False),\n","                    metrics=['accuracy'])"],"metadata":{"id":"hDoqZtUEeLx3","executionInfo":{"status":"ok","timestamp":1696402395292,"user_tz":-660,"elapsed":3553,"user":{"displayName":"Nick Eales","userId":"12867207549321056565"}},"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","outputId":"afbd47cd-fd62-4a3d-d557-f4bd63873254"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.13.0\n","building Xception model\n"]}]},{"cell_type":"markdown","source":["===================<br>\n","**Fifth Section**\n"," - Load datasets"],"metadata":{"id":"hmM_FaEKa7Iu"}},{"cell_type":"code","source":["# @title\n","print('loading training dataset')\n","train_ds=tf.keras.utils.image_dataset_from_directory(train_dataset_dir,labels='inferred',label_mode=label_mode,image_size=preferred_image_size)\n","print('loading validation dataset')\n","validation_ds=tf.keras.utils.image_dataset_from_directory(val_dataset_dir,labels='inferred',label_mode=label_mode,image_size=preferred_image_size)\n","print('loading test dataset')\n","test_ds=tf.keras.utils.image_dataset_from_directory(test_dataset_dir,labels='inferred',label_mode=label_mode,image_size=preferred_image_size)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKS2Z7m27OQ9","outputId":"d53c764c-db36-496d-99ee-b2900f64822b","cellView":"form","executionInfo":{"status":"ok","timestamp":1696400270631,"user_tz":-660,"elapsed":1762,"user":{"displayName":"Nick Eales","userId":"12867207549321056565"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["loading training dataset\n","Found 18728 files belonging to 2 classes.\n","loading validation dataset\n","Found 2340 files belonging to 2 classes.\n","loading test dataset\n","Found 2342 files belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":["===================<br>\n","**Sixth Section** ***(Optional)***\n","- Get the accuracy of the model against the test dataset prior to any training - use for comparison purposes"],"metadata":{"id":"BG6oqmiPbCYl"}},{"cell_type":"code","source":["# @title\n","#Evaluate accuracy without further training.\n","\n","#evaluate takes ~15 min on colab when using CPU or ~ 30s when using GPU (once data is loaded)\n","(initialAccuracy,initial_loss)=model.evaluate(test_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"4h7uCrSwZRon","executionInfo":{"status":"ok","timestamp":1696402324122,"user_tz":-660,"elapsed":18139,"user":{"displayName":"Nick Eales","userId":"12867207549321056565"}},"outputId":"c13f2271-1745-4ba3-d119-5fd0dcfa225e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["74/74 [==============================] - 18s 214ms/step - loss: 0.6545 - accuracy: 0.6661\n"]}]},{"cell_type":"markdown","source":["===================<br>\n","**Seventh Section**\n","1. Build callbacks\n","  - Early Stopping - if validation accuracy isn't improving\n","  - reduceLrOnPlateau - if training accuracy isn't improving (do this sooner than the early stopping one\n","  - Checkpoint - save a copy of the model when the best results are obtained (useful if google colab session times out). The methods to load this are beyond the scope of this notebook.\n","\n","2. setup dataset autotuning. In theory this speeds up training by reducing idle time on GPU - by ensuring fresh data is available for processing all the time.\n","\n","3. start the training. This takes a while - especially if training from random weights.\n","Note the number of trainable parameters in use - this changes depending on whether random weights are used or imagenet weights are used."],"metadata":{"id":"fs-6z26AbXeH"}},{"cell_type":"code","source":["# @title\n","# Setup callbacks\n","#then try & train the model.\n","\n","import time\n","\n","base_learning_rate=0.02\n","#Early Stopping Patience (epoch Count)\n","es_patience=5\n","#Learning Rate Patience (epoch Count)\n","lr_patience=3\n","initial_epoch=0\n","epochs=30\n","\n","train_id = str(int(time.time()))\n","\n","callbacks=[]\n","callbacks = callbacks + [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=es_patience)]\n","callbacks=callbacks +[tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.2, min_delta=0.005,\n","                      patience=lr_patience, min_lr=0.000001)]\n","checkpoint_dir=os.path.join(output_dir,'checkpoints')\n","if not os.path.isdir(checkpoint_dir):\n","    os.mkdir(checkpoint_dir)\n","\n","callbacks=callbacks +[tf.keras.callbacks.ModelCheckpoint(\n","    checkpoint_dir,\n","    monitor='val_accuracy',\n","    verbose=0,\n","    save_best_only=True,\n","    mode='auto',\n","    save_freq='epoch')]\n","\n","\n","model.summary(show_trainable=True)\n","# set up autotuning to try & speed things up:\n","AUTOTUNE = tf.data.AUTOTUNE\n","train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n","validation_ds = validation_ds.prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n","print(\"training\")\n","\n","print(f\"es_patience={es_patience}\")\n","print(f\"lr_patience={lr_patience} (current: {base_learning_rate})\")\n","\n","history = model.fit(train_ds,\n","    initial_epoch=initial_epoch,\n","    epochs=(initial_epoch+epochs),\n","    validation_data=validation_ds,\n","    callbacks=callbacks,\n","    validation_freq=1)\n","initial_epoch=history.epoch[-1]+1\n","\n","if(history.epoch[-1] <= (epochs-1)):\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","loss, accuracy = model.evaluate(test_ds)\n","print(f\"{architecture} - Test accuracy :\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"qwExAnKqPU_p","outputId":"9ad8b6cf-6e2d-49e6-f846-003c2fbdb990"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","____________________________________________________________________________\n"," Layer (type)                Output Shape              Param #   Trainable  \n","============================================================================\n"," input_2 (InputLayer)        [(None, 299, 299, 3)]     0         Y          \n","                                                                            \n"," RandomFlipRotateZoom (Sequ  (None, 299, 299, 3)       0         Y          \n"," ential)                                                                    \n","                                                                            \n"," tf.math.truediv (TFOpLambd  (None, 299, 299, 3)       0         Y          \n"," a)                                                                         \n","                                                                            \n"," tf.math.subtract (TFOpLamb  (None, 299, 299, 3)       0         Y          \n"," da)                                                                        \n","                                                                            \n"," xception (Functional)       (None, 2048)              2086148   N          \n","                                                       0                    \n","                                                                            \n"," dropout (Dropout)           (None, 2048)              0         Y          \n","                                                                            \n"," dense (Dense)               (None, 1)                 2049      Y          \n","                                                                            \n","============================================================================\n","Total params: 20863529 (79.59 MB)\n","Trainable params: 2049 (8.00 KB)\n","Non-trainable params: 20861480 (79.58 MB)\n","____________________________________________________________________________\n","training\n","es_patience=5\n","lr_patience=3 (current: 0.02)\n","Epoch 1/30\n","586/586 [==============================] - 179s 297ms/step - loss: 0.1824 - accuracy: 0.9349 - val_loss: 0.0418 - val_accuracy: 0.9910 - lr: 0.0010\n","Epoch 2/30\n","586/586 [==============================] - 177s 301ms/step - loss: 0.1237 - accuracy: 0.9527 - val_loss: 0.0332 - val_accuracy: 0.9915 - lr: 0.0010\n","Epoch 3/30\n","586/586 [==============================] - 159s 270ms/step - loss: 0.1137 - accuracy: 0.9553 - val_loss: 0.0316 - val_accuracy: 0.9910 - lr: 0.0010\n","Epoch 4/30\n","586/586 [==============================] - 172s 293ms/step - loss: 0.1139 - accuracy: 0.9568 - val_loss: 0.0301 - val_accuracy: 0.9923 - lr: 0.0010\n","Epoch 5/30\n","586/586 [==============================] - 157s 268ms/step - loss: 0.1105 - accuracy: 0.9564 - val_loss: 0.0286 - val_accuracy: 0.9919 - lr: 0.0010\n","Epoch 6/30\n","586/586 [==============================] - 157s 267ms/step - loss: 0.1089 - accuracy: 0.9579 - val_loss: 0.0287 - val_accuracy: 0.9919 - lr: 2.0000e-04\n"]}]},{"cell_type":"markdown","source":["===================<br>\n","**Eighth section**\n","- Save the model"],"metadata":{"id":"u_tfyS0DeJu9"}},{"cell_type":"code","source":["# @title\n","model_path=os.path.join(output_dir\n","        ,'saved_models')\n","if not os.path.isdir(model_path):\n","    os.mkdir(model_path)\n","save_path = os.path.join(model_path,\n","        f'{architecture}_{train_id}')\n","print(f'saving {architecture} model to file \"{save_path}\"')\n","model.save(save_path)\n","\n"],"metadata":{"cellView":"form","id":"bbII53EzRSVd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["===================<br>\n","**Ninth Section**\n","- Plot training results."],"metadata":{"id":"_qfQ7otqePHe"}},{"cell_type":"code","source":["# @title\n","\n","plot_model_filepath=os.path.join(output_dir,f'{architecture}_model.png')\n","tf.keras.utils.plot_model(model,to_file=plot_model_filepath)\n","\n","fig, (ax1, ax2) = plt.subplots(2, 1)\n","ax1.plot(acc, label='Training Accuracy')\n","ax1.plot(val_acc, label='Validation Accuracy')\n","ax1.set_ylim([0.5, 1])\n","#if weights == 'imagenet':\n","#    ax1.plot([epochs-1,epochs-1],\n","#        ax1.get_ylim(), label='Start Fine Tuning')\n","ax1.legend(loc='lower right')\n","ax1.set_title(f'{architecture} Training and Validation Accuracy ')\n","\n","ax2.plot(loss, label='Training Loss')\n","ax2.plot(val_loss, label='Validation Loss')\n","ax2.set_ylim([0, 1.0])\n","#if weights == 'imagenet':\n","#    ax2.plot([epochs-1,epochs-1],\n","#        ax2.get_ylim(), label='Start Fine Tuning')\n","ax2.legend(loc='upper right')\n","ax2.set_title('Training and Validation Loss')\n","ax2.set_xlabel('epoch')\n","fig.tight_layout()\n","fig_filename=os.path.join(f'{output_dir}',\n","        f'{architecture}-{epochs}-{epochs}-{weights}-{train_id}')\n","fig.savefig(fname=fig_filename)\n"],"metadata":{"cellView":"form","id":"6YQzrVOVSvkR"},"execution_count":null,"outputs":[]}]}